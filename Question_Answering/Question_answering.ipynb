{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "torch.random.manual_seed(13)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ELMO import ELMo\n",
    "import wandb\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file\n",
    "with open('wiki-cloze/mr.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "torch.manual_seed(13)\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from preprocessing import tokenize, convert_to_oov, CharLevelVocab, WordLevelVocab\n",
    "\n",
    "\n",
    "OUT_OF_VOCAB = '<OOV>'\n",
    "PAD_TAG = '<PAD>'\n",
    "START_TAG = '<BOS>'\n",
    "END_TAG = '<EOS>'\n",
    "\n",
    "\n",
    "\n",
    "class QuestionAnsweringDataset(Dataset):\n",
    "    def __init__(self, question, answers, correct_answer, word_vocab: WordLevelVocab, char_vocab: CharLevelVocab, max_seq_length=50, max_word_length=10):\n",
    "        self.question = tokenize(question)\n",
    "        self.answers = answers\n",
    "        self.correct_answer = correct_answer\n",
    "        self.word_vocab = word_vocab\n",
    "        self.char_vocab = char_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_word_length = max_word_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # i have 4 answers. I need to return 4 sentences with the <MASK> token replaced with the 4 different answers\n",
    "        question = self.question[idx]\n",
    "        answers = self.answers[idx]\n",
    "        # replace mask with <> token\n",
    "        question = [word if word != 'MASK' else '<>' for word in question]\n",
    "\n",
    "\n",
    "        onehot = []\n",
    "        for i in range(4):\n",
    "            if answers[i] == self.correct_answer[idx]:\n",
    "                onehot.append(1)\n",
    "            else:\n",
    "                onehot.append(0)\n",
    "\n",
    "\n",
    "        return [torch.tensor([self.char_vocab.char_to_index(char) for char in word], dtype=torch.long) for word in question], \\\n",
    "               [torch.tensor([self.char_vocab.char_to_index(char) for char in word], dtype=torch.long) for word in answers], \\\n",
    "               torch.tensor(onehot, dtype=torch.float32)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        questions, answers, onehot = zip(*batch)\n",
    "        bos_token = []\n",
    "        for c in START_TAG:\n",
    "            bos_token.append(self.char_vocab.char_to_index(c))\n",
    "        bos_token = torch.tensor(bos_token, dtype=torch.long)\n",
    "        eos_token = []\n",
    "        for c in END_TAG:\n",
    "            eos_token.append(self.char_vocab.char_to_index(c))\n",
    "        eos_token = torch.tensor(eos_token, dtype=torch.long)\n",
    "        pad_token = []\n",
    "        for c in PAD_TAG:\n",
    "            pad_token.append(self.char_vocab.char_to_index(c))\n",
    "        pad_token = torch.tensor(pad_token, dtype=torch.long)\n",
    "\n",
    "        middle_token = []\n",
    "        for c in \"<>\":\n",
    "            middle_token.append(self.char_vocab.char_to_index(c))\n",
    "        middle_token = torch.tensor(middle_token, dtype=torch.long)\n",
    "\n",
    "        questions = [[bos_token] + sentence for sentence in questions]\n",
    "\n",
    "        questions = [sentence[:self.max_seq_length] + [pad_token] * (self.max_seq_length - len(sentence)) for sentence in questions]\n",
    "\n",
    "        # add the answers to the questions\n",
    "        for i in range(len(questions)):\n",
    "            for j in range(len(answers[i])):\n",
    "                questions[i].append(middle_token)\n",
    "                questions[i].append(answers[i][j])\n",
    "        \n",
    "        # add the end token\n",
    "        for i in range(len(questions)):\n",
    "            questions[i].append(eos_token)\n",
    "\n",
    "        for i in range(len(questions)):\n",
    "            for j in range(len(questions[i])):\n",
    "                questions[i][j] = torch.cat([questions[i][j][:self.max_word_length], torch.tensor([self.char_vocab.char_to_index(PAD_TAG)]*(self.max_word_length - len(questions[i][j])), dtype=torch.long)])\n",
    "\n",
    "        questions = torch.stack([torch.stack(sentence) for sentence in questions])\n",
    "        \n",
    "        onehot = torch.stack(onehot)\n",
    "        return questions, onehot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [data['cloze_data'][i]['question'] for i in range(len(data['cloze_data']))]\n",
    "options = [data['cloze_data'][i]['options'] for i in range(len(data['cloze_data']))]\n",
    "answers = [data['cloze_data'][i]['answer'] for i in range(len(data['cloze_data']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word and character vocabulary\n",
    "char_vocab = torch.load('../ELMo/char_vocab_marathi.pt')\n",
    "word_vocab = torch.load('../ELMo/word_vocab_marathi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QuestionAnsweringDataset(questions, options, answers, word_vocab, char_vocab, max_seq_length=30, max_word_length=10)\n",
    "# split into train, val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswering(nn.Module):\n",
    "    def __init__(self, elmo, embedding_dim, num_classes):\n",
    "        super(QuestionAnswering, self).__init__()\n",
    "        self.elmo = elmo\n",
    "        self.fc = nn.Linear(embedding_dim, embedding_dim//2)\n",
    "        self.fc2 = nn.Linear(embedding_dim//2, embedding_dim//4)\n",
    "        self.fc3 = nn.Linear(embedding_dim//4, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lambdas = nn.Parameter(torch.rand(3))\n",
    "\n",
    "        for param in self.elmo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, questions):\n",
    "        _, _, questions = self.elmo(questions)\n",
    "      \n",
    "        encoding = torch.zeros_like(questions[0])\n",
    "\n",
    "        for i in range(3):\n",
    "            encoding += self.lambdas[i] * questions[i]\n",
    "        selected_encodings = [encoding[:,-8,:], encoding[:,-6,:], encoding[:,-4,:], encoding[:,-2,:]]\n",
    "        # stack\n",
    "        selected_encodings = torch.stack(selected_encodings, dim=1)\n",
    "        # take mean of the embeddings\n",
    "        selected_encodings = torch.mean(selected_encodings, dim=1)\n",
    "        # take mean of second last, 4th last, 6th last and 8th last layer\n",
    "        x = self.fc(selected_encodings)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = ELMo(cnn_config = {'character_embedding_size': 16, \n",
    "                           'num_filters': 32, \n",
    "                           'kernel_size': 5, \n",
    "                           'max_word_length': 10, \n",
    "                           'char_vocab_size': char_vocab.num_chars}, \n",
    "             elmo_config = {'num_layers': 3,\n",
    "                            'word_embedding_dim': 150,\n",
    "                            'vocab_size': word_vocab.num_words}, \n",
    "             char_vocab_size = char_vocab.num_chars).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo.load_state_dict(torch.load('../ELMo/elmo_epoch_3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering = QuestionAnswering(elmo, 300, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_question(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            # q1, q2, q3, q4, target = batch\n",
    "            optimizer.zero_grad()\n",
    "            # q1 = q1.to(device)\n",
    "            # q2 = q2.to(device)\n",
    "            # q3 = q3.to(device)\n",
    "            # q4 = q4.to(device)\n",
    "            # output = model(q1, q2, q3, q4)\n",
    "            questions, target = batch\n",
    "            questions = questions.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(questions)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            predictions.extend(torch.argmax(output, dim=1).tolist())\n",
    "            targets.extend(torch.argmax(target, dim=1).tolist())\n",
    "        print('Epoch:', epoch, 'Loss:', total_loss)\n",
    "        print('Accuracy:', sum([1 for i in range(len(predictions)) if predictions[i] == targets[i]])/len(predictions))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            predictions = []\n",
    "            targets = []\n",
    "            for batch in tqdm(val_loader):\n",
    "                # q1, q2, q3, q4, target = batch\n",
    "                # q1 = q1.to(device)\n",
    "                # q2 = q2.to(device)\n",
    "                # q3 = q3.to(device)\n",
    "                # q4 = q4.to(device)\n",
    "                questions, target = batch\n",
    "                questions = questions.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(questions)\n",
    "                target = target.to(device)\n",
    "                loss = criterion(output, target)\n",
    "                total_loss += loss.item()\n",
    "                predictions.extend(torch.argmax(output, dim=1).tolist())\n",
    "                targets.extend(torch.argmax(target, dim=1).tolist())\n",
    "            print('Val Loss:', total_loss)\n",
    "            print('Val Accuracy:', sum([1 for i in range(len(predictions)) if predictions[i] == targets[i]])/len(predictions))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(question_answering.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 397.0885375738144\n",
      "Accuracy: 0.24472295514511874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 99.90960466861725\n",
      "Val Accuracy: 0.24626209322779244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 395.5011662244797\n",
      "Accuracy: 0.25395778364116095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 99.89568102359772\n",
      "Val Accuracy: 0.2519788918205805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 395.18937361240387\n",
      "Accuracy: 0.2615435356200528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.15773093700409\n",
      "Val Accuracy: 0.23702726473175023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 394.9826751947403\n",
      "Accuracy: 0.26824978012313105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.15262377262115\n",
      "Val Accuracy: 0.23878627968337732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 394.55707013607025\n",
      "Accuracy: 0.27341688654353563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.10006392002106\n",
      "Val Accuracy: 0.23922603342128407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 393.7376916408539\n",
      "Accuracy: 0.2773746701846966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.96801340579987\n",
      "Val Accuracy: 0.23746701846965698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 393.3480746746063\n",
      "Accuracy: 0.28924802110817943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.24395418167114\n",
      "Val Accuracy: 0.2704485488126649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 392.3604700565338\n",
      "Accuracy: 0.28770888302550574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:06<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.40632259845734\n",
      "Val Accuracy: 0.2546174142480211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 390.7692667245865\n",
      "Accuracy: 0.3005716798592788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 100.5695880651474\n",
      "Val Accuracy: 0.2598944591029024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:28<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 389.617115855217\n",
      "Accuracy: 0.3016710642040457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:07<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 101.78613924980164\n",
      "Val Accuracy: 0.2546174142480211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_question(question_answering, train_dataloader, val_dataloader, optimizer, criterion, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question answering is not a valid task, because all of the questions in the dataset are extremely specific and related to places. The only learning the model does is by overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
