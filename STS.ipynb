{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from ELMO import ELMo\n",
    "import torch.nn.functional as F\n",
    "from sts_loader import STSDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabularies\n",
    "vocab = torch.load('Hin_vocab.pt')\n",
    "character_vocab = torch.load('Hin_character_vocab.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanve\\AppData\\Local\\Temp\\ipykernel_27996\\1617589287.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scores = torch.tensor(scores, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Get Sentences and Scores\n",
    "\n",
    "path = 'sts-train-hi.tsv'\n",
    "sts_dataset = STSDataset(path)\n",
    "s1, s2, scores = sts_dataset.format(character_vocab)\n",
    "scores = torch.tensor(scores, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(s1, s2, scores, batch_size):\n",
    "    zipped = list(zip(s1, s2, scores))\n",
    "    dataloader = DataLoader(zipped, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the dataloader\n",
    "s1_val = s1[:1000]\n",
    "s2_val = s2[:1000]\n",
    "scores_val = scores[:1000]\n",
    "batch_size = 64\n",
    "val_dataloader = create_dataloader(s1_val, s2_val, scores_val, batch_size)\n",
    "train_dataloader = create_dataloader(s1[1000:], s2[1000:], scores[1000:], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     for j in range(15):\n",
    "#         print(s1[i][j], s2[i][j], scores[i])\n",
    "#     print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ELMo(cnn_config = {'character_embedding_size': 16, \n",
    "                           'num_filters': 32, \n",
    "                           'kernel_size': 5, \n",
    "                           'max_word_length': 10, \n",
    "                           'char_vocab_size': len(character_vocab)}, \n",
    "             elmo_config = {'num_layers': 3,\n",
    "                            'word_embedding_dim': 300,\n",
    "                            'vocab_size': len(vocab)}, \n",
    "             char_vocab_size = len(character_vocab)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Hin_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim = 300\n",
    "\n",
    "\n",
    "class SimilarityModel(nn.Module):\n",
    "    def __init__(self, elmo):\n",
    "        super(SimilarityModel, self).__init__()\n",
    "        self.elmo = elmo        \n",
    "        self.lstm = nn.LSTM(word_embedding_dim, word_embedding_dim//2, bidirectional=True)\n",
    "        \n",
    "    def forward(self, sentence1, sentence2):\n",
    "        _, sentence1 = self.elmo(sentence1)\n",
    "        _, sentence2 = self.elmo(sentence2)\n",
    "        # print the embeddings of the first sentence\n",
    "        # print(sentence1.shape, sentence2.shape)\n",
    "\n",
    "        lstm_out1, _ = self.lstm(sentence1)\n",
    "        lstm_out2, _ = self.lstm(sentence2)\n",
    "        # print(lstm_out1.shape, lstm_out2.shape)\n",
    "        last_output1 = lstm_out1[:, -1, :]\n",
    "        last_output2 = lstm_out2[:, -1, :]\n",
    "        # print(lstm_out1.shape, lstm_out2.shape)\n",
    "        lstm_out1 = lstm_out1.view(lstm_out1.size(0), -1)  \n",
    "        lstm_out2 = lstm_out2.view(lstm_out2.size(0), -1)  \n",
    "\n",
    "        # Compute the cosine similarity between the reshaped tensors\n",
    "        cos_sim = (F.cosine_similarity(lstm_out1, lstm_out2, dim=1) + 1)*5/2\n",
    "        # print((F.cosine_similarity(lstm_out1, lstm_out2, dim=0) + 1)*5/2)\n",
    "        return cos_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_model = SimilarityModel(model)\n",
    "similarity_model = SimilarityModel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(similarity_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:20<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 166.7070243358612\n",
      "Validation Loss: 66.03542757034302 Mean Difference: 1.6704048080444336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:19<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 153.29780983924866\n",
      "Validation Loss: 56.270490884780884 Mean Difference: 1.567905460357666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:19<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 151.6114535331726\n",
      "Validation Loss: 54.99734425544739 Mean Difference: 1.5563747329711914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:20<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 152.36556661128998\n",
      "Validation Loss: 53.552475690841675 Mean Difference: 1.5436703872680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 29/75 [00:08<00:13,  3.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(outputs.squeeze().shape, scores.shape)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(outputs.shape, scores.shape)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, scores)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\tanve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tanve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    similarity_model.train()\n",
    "    total_loss = 0\n",
    "    for s1, s2, scores in tqdm(train_dataloader):\n",
    "        s1 = s1\n",
    "        s2 = s2\n",
    "        scores = scores.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = similarity_model(s1, s2)\n",
    "        # print(outputs.squeeze().shape, scores.shape)\n",
    "        # print(outputs.shape, scores.shape)\n",
    "        loss = criterion(outputs, scores)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} Loss: {total_loss}\")\n",
    "\n",
    "    similarity_model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        # calculate mean difference between predicted and actual scores\n",
    "        diff = 0\n",
    "\n",
    "        for s1, s2, scores in val_dataloader:\n",
    "            s1 = s1\n",
    "            s2 = s2\n",
    "            scores = scores.to(device)\n",
    "            outputs = similarity_model(s1, s2)\n",
    "            loss = criterion(outputs, scores)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            diff += torch.abs(outputs - scores).sum().item()\n",
    "            # calculate \n",
    "\n",
    "        print(f\"Validation Loss: {total_loss}\" + f\" Mean Difference: {diff/len(s1_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
