{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n",
    "import pandas as pd\n",
    "from preprocessing import tokenize, split_into_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_OF_VOCAB = '<OOV>'\n",
    "PAD_TAG = '<PAD>'\n",
    "START_TAG = '<BOS>'\n",
    "END_TAG = '<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5.00\n",
       "1       3.80\n",
       "2       3.80\n",
       "3       2.60\n",
       "4       4.25\n",
       "        ... \n",
       "5744    0.00\n",
       "5745    0.00\n",
       "5746    0.00\n",
       "5747    0.00\n",
       "5748    0.00\n",
       "Name: 4, Length: 5749, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class STSDataset(Dataset):\n",
    "    def __init__(self, path, start=0, end=100000, vocabulary = None):\n",
    "        df = pd.read_csv(path, sep='\\t', header=None)\n",
    "        sens1 = df[5]\n",
    "        sens2 = df[6]\n",
    "        scores = df[4]\n",
    "        self.vocaulary = vocabulary\n",
    "        self.sentences1 = tokenize(sens1)\n",
    "        self.sentences2 = tokenize(sens2)\n",
    "        self.scores = scores\n",
    "        print(\"Tokenized data\")\n",
    "        print(self.sentences1[:10])\n",
    "        # if vocabulary is None:\n",
    "        #     self.vocab = build_vocab_from_iterator(self.sentences1, specials=[OUT_OF_VOCAB, PAD_TAG, START_TAG, END_TAG])\n",
    "        #     self.vocab.set_default_index(self.vocab[OUT_OF_VOCAB])\n",
    "        # else:\n",
    "        #     self.vocab = vocabulary\n",
    "\n",
    "        # self.vocab.set_default_index(self.vocab['<OOV>'])\n",
    "        # iterate over the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.sentences1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s1 = [self.vocabulary[word] if word in self.vocabulary else self.vocabulary[OUT_OF_VOCAB] for word in self.sentences1[idx]]\n",
    "        s2 = [self.vocabulary[word] if word in self.vocabulary else self.vocabulary[OUT_OF_VOCAB] for word in self.sentences2[idx]]\n",
    "        return s1, s2, self.scores[idx]\n",
    "\n",
    "    \n",
    "    def format(self, batch, window_size) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # convert the batch into a tensor\n",
    "        # convert the batch into a tensor\n",
    "        # pad the batch\n",
    "        words = []\n",
    "        targets = []\n",
    "        # iterate over the batch\n",
    "        for sentence in batch:\n",
    "            for i in range(len(sentence) - window_size):\n",
    "                words.append(sentence[i:i+window_size])\n",
    "                targets.append(sentence[i+window_size])\n",
    "        # convert the words and targets into tensors\n",
    "        self.words, self.character_vocab = split_into_characters(words, 10)\n",
    "        # convert self.vocab into a dictionary and self.character_vocab into a dictionary\n",
    "        vocab = {}\n",
    "        for i, word in enumerate(self.vocab.get_itos()):\n",
    "            vocab[word] = i\n",
    "        character_vocab = {}\n",
    "        for i, char in enumerate(self.character_vocab.keys()):\n",
    "            character_vocab[char] = i\n",
    "        words_tensor, targets = convert_to_tensors(self.words, targets, vocab, character_vocab)\n",
    "        return words_tensor, targets, vocab, character_vocab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
